# RAG-Based LLM Application with LlamaIndex and OpenAI for Multi-PDF Indexing & Querying

## üöÄ Project Overview
This project is an end-to-end **Retrieval-Augmented Generation (RAG) LLM App** that leverages **LlamaIndex** and **OpenAI** to index and query multiple PDF documents. The application allows users to retrieve information from large document collections using AI-powered natural language queries.

##  Project Aim
- Implement a **RAG pipeline** using **LlamaIndex** and **OpenAI**.
- Efficiently **index multiple PDFs** for structured querying.
- Enable **semantic search** and **context-aware responses**.

##  Tech Stack
- **Python**
- **LlamaIndex** (Formerly GPT Index)
- **OpenAI API**
- **LangChain**

## üîß Installation & Setup
### 1Ô∏è‚É£ Clone the Repository
```sh
git clone https://github.com/your-username/RAG-LLM-App.git
cd RAG-LLM-App
```
### 2Ô∏è‚É£ Install Dependencies
```sh
pip install -r requirements.txt
```
### 3Ô∏è‚É£ Set Up API Keys
Create a `.env` file and add your **OpenAI API Key**:
```env
OPENAI_API_KEY=your_openai_api_key
```

### 4Ô∏è‚É£ Run the App
```sh
streamlit run src/app.py
```

## üìù Usage
1. **Upload PDFs** via the UI.
2. **Index the documents** using LlamaIndex.
3. **Ask natural language queries** and get AI-powered answers.




